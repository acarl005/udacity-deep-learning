{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in _notmist.ipynb_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (187473, 28, 28) (187473,)\n",
      "Validation set (9867, 28, 28) (9867,)\n",
      "Test set (9788, 28, 28) (9788,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (187473, 784) (187473, 10)\n",
      "Validation set (9867, 784) (9867, 10)\n",
      "Test set (9788, 784) (9788, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_logits(dataset, *layers):\n",
    "    # variable for the current layer\n",
    "    activations = dataset\n",
    "    # apply each layer to the previous\n",
    "    for i, layer in enumerate(layers):\n",
    "        activations = tf.matmul(activations, layer[0]) + layer[1]\n",
    "        # run a ReLU in between each layer, but not on the final layer\n",
    "        if i < len(layers) - 1:\n",
    "            activations = tf.nn.relu(activations)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "learning_rate = 0.5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape=(batch_size, image_size ** 2))\n",
    "    tf_train_labels = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    regul_coeff = tf.placeholder(tf.float32)\n",
    "    \n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([image_size ** 2, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    logits = calc_logits(tf_train_dataset, [weights, biases])\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    loss += regul_coeff * tf.nn.l2_loss(weights)\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(calc_logits(tf_valid_dataset, [weights, biases]))\n",
    "    test_prediction = tf.nn.softmax(calc_logits(tf_test_dataset, [weights, biases]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngwkqwOQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f466d075978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run(num_steps, regul_coeff_val, verbose=False):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (len(train_labels) - batch_size)\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            data = {\n",
    "                tf_train_dataset: batch_data,\n",
    "                tf_train_labels: batch_labels,\n",
    "                regul_coeff: regul_coeff_val }\n",
    "            \n",
    "            _, l, predictions = session.run(\n",
    "                [optimizer, loss, train_prediction],\n",
    "                feed_dict=data)\n",
    "            \n",
    "            if verbose and step % 500 == 0:\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "        \n",
    "        return accuracy(test_prediction.eval(), test_labels)\n",
    "\n",
    "\n",
    "regul_coeffs = np.power(10, np.arange(-4.1, -1.7, 0.1), dtype=np.float32)\n",
    "%time accuracy_vals = [run(3001, regul_coeff) for regul_coeff in regul_coeffs]\n",
    "plt.semilogx(regul_coeffs, accuracy_vals)\n",
    "plt.title('Test accuracy vs regularization coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal regularization parameter:\n",
      "0.00125893\n"
     ]
    }
   ],
   "source": [
    "print('Optimal regularization parameter:')\n",
    "print(regul_coeffs[np.argmax(accuracy_vals)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 0: 27.143448\n",
      "Minibatch accuracy: 3.1%\n",
      "Validation accuracy: 9.8%\n",
      "Minibatch loss at step 500: 2.719204\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 1000: 1.190569\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 1500: 0.742051\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2000: 0.658904\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2500: 0.662327\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 0.964299\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.5%\n",
      "CPU times: user 9.22 s, sys: 1.62 s, total: 10.8 s\n",
      "Wall time: 8.46 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88.904781364936653"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time run(3001, 2e-3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "learning_rate = 0.5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape=(batch_size, image_size ** 2))\n",
    "    tf_train_labels = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    regul_coeff = tf.placeholder(tf.float32)\n",
    "    \n",
    "    weights1 = tf.Variable(\n",
    "        tf.truncated_normal([image_size ** 2, num_hidden_nodes]))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    weights2 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "    layers = [\n",
    "        [weights1, biases1],\n",
    "        [weights2, biases2]]\n",
    "    \n",
    "    logits = calc_logits(tf_train_dataset, *layers)\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    loss += regul_coeff * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2))\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(calc_logits(tf_valid_dataset, *layers))\n",
    "    test_prediction = tf.nn.softmax(calc_logits(tf_test_dataset, *layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 12.4 s, total: 1min 16s\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEOCAYAAABy7Vf3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUoSU3EVEitD/AYNnn/Mu3TvyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95c36eceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run(num_steps, regul_coeff_val, verbose=False):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (len(train_labels) - batch_size)\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            data = {\n",
    "                tf_train_dataset: batch_data,\n",
    "                tf_train_labels: batch_labels,\n",
    "                regul_coeff: regul_coeff_val }\n",
    "        \n",
    "            _, l, predictions = session.run(\n",
    "                [optimizer, loss, train_prediction],\n",
    "                feed_dict=data)\n",
    "            \n",
    "            if verbose and step % 500 == 0:\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "                \n",
    "        return accuracy(test_prediction.eval(), test_labels)\n",
    "  \n",
    "\n",
    "regul_coeffs = np.power(10, np.arange(-2.7, -0.9, 0.1), dtype=np.float32)\n",
    "%time accuracy_vals = [run(501, regul_coeff) for regul_coeff in regul_coeffs]\n",
    "plt.semilogx(regul_coeffs, accuracy_vals)\n",
    "plt.title('Test accuracy vs regularization coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal regularization parameter:\n",
      "0.00794328\n"
     ]
    }
   ],
   "source": [
    "print('Optimal regularization parameter:')\n",
    "print(regul_coeffs[np.argmax(accuracy_vals)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 0: 2817.831055\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 27.4%\n",
      "Minibatch loss at step 500: 46.506756\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.6%\n",
      "CPU times: user 3.73 s, sys: 636 ms, total: 4.36 s\n",
      "Wall time: 4.83 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.37719656722517"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time run(501, 0.00794, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
